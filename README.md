# Stage m2 : higgs events production modes classification



#### Using Monte-Carlo simulated data, train Machine Learning classifiers to reconstruct the production modes of Higgs bosons decaying in the Golden Channel. The performance of the models can be evaluated either directly from their category content plot, or from our custom  "Specificity vs Acceptance" curves (in this implementation, only the metrics on VBF category are considered).


The program uses both ROOT, rootpy and root_numpy, all these should be installed on your system in order to generate the datasets.
We also left the program in a state where it trains our best candidate, the xgboosted trees. Therefore, one should install XGBOOst following the instructions from http://xgboost.readthedocs.io/en/latest/build.html 


## Details:

Most of the program's behavior is controlled from three files: 

- __main.py__ will load all necessary components from the "core" package, and execute them. By acting on this file, one modifies which components of the package will be executed, especially whether or not to compute or recompute certain results. 

- __core\constants.py__ contains most of the parameters controlling the way the functions in the core package are executed. These are meant to be easy to modify without having to change anything in the rest of the package. The most important variables in this module are the list of features, as well as the dictionary of ML models with their associated filename.

- __core\preprocessing.py__ contains the remaining parameters, namely the ones necessary for the preprocessing step. In particular, this is where quantities to retrieve, compute, and remove from the ROOT files for each features set are defined.


the intended behavior is the following :

- __core\preprocessing.py__ takes as an input the full ROOT files for the simulated data in each of the production channels. It returns properly formatted and scaled datasets (scaling is necessary for certain algorithms to perform well) with only the wanted features. It also allows to add calculated features, using either python function or C functions loaded through ROOT.

- __core\trainer.py__ is then called to fit a model on the training set generated by \textbf{preprocessing}. The model is stored as a serialized pickle object, along with its predictions on the datasets.

- __core\evaluation__ is then used to generate the evaluation metrics for the models previously trained. The save of the predictions made by __trainer__ is very useful to make this step fast as it avoids having to regenerate the predictions, a process which might be long depending on the model we are considering.

- __core/roc_curve.py__  provides template functions for custom evaluation, especially our 2D plot of VBF specificity vs acceptance.

